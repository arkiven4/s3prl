runner:
  n_epochs: -1
  total_steps: 1000000
  gradient_clipping: 5.0
  gradient_accumulate_steps: 1

  log_step: 100
  save_step: 10000
  max_keep: 10

  fp16: false

optimizer:
  name: AdamW_with_schedule
  lr: 2.e-4
  warmup_proportion: 0.08

pretrain_expert:
  datarc:
    num_workers: 8
    train_batch_size: 4
    max_timestep: 0 # Max length for audio feature (0 for no restriction, negative value to set minimum timestep)
    #libri_root: /home/is/dwipraseetyo-a/NAS_HAI/Project/s3prl/s3prl/data/libri_mel160 #'/home/is/dwipraseetyo-a/NAS_HAI/Datasets/' # If raw libri data is provided, use on-the-fly feature extraction, else use the pre-extracted features under `file_path`
    file_path: 'data/libri_mel80' # Pre-extracted features path. When using on-the-fly feature extraction, this is used to provide length for bucketing.
    sets: ['train', 'test', 'test'] # can be the subset of ['train-clean-100', 'train-clean-360', 'train-other-500']